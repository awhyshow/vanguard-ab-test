{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4fa89ec",
   "metadata": {},
   "source": [
    "# *Project: Vanguard A/B Test Results Analysis*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfe467",
   "metadata": {},
   "source": [
    "### CONTEXT:\n",
    "- Company : Vanguard, the US-based investment management company. (website: https://investor.vanguard.com/)- Role : newly hired DATA ANALYST in the Customer Experience (CX) team. \n",
    "The team launched an exciting digital experiment, and now, they're eagerly waiting to uncover the results and need your help!\n",
    "- Task : Analyze the results of the digital experiment conducted by the team.Primary objective:  Decode the experiment's performance.\n",
    "- The critical question : Would these changes encourage more clients to complete the process?\n",
    "- Belief : Vanguard believed that a more intuitive, modern UI with timely in-context prompts (cues, messages, or instructions within the user’s current task) could make the online process smoother for clients.\n",
    "---\n",
    "An **A/B test** was set **into motion** `from 3/15/2017 to 6/20/2017` by the team.\n",
    "- Control Group: Clients interacted with Vanguard's traditional online process. (old UI)- Test Group: Clients experienced the new, spruced-up digital interface. (new UI)\n",
    "---\n",
    "\n",
    "Both groups navigated through an identical process sequence:\n",
    "- an initial page (start), \n",
    "- three subsequent steps (step 1, step 2, step 3), \n",
    "- and finally, a confirmation page signaling process completion.\n",
    "---\n",
    "**The goal is to see if the new design leads to a better user experience and higher process completion rates.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cfce0",
   "metadata": {},
   "source": [
    "---\n",
    "### STEP 01: Merging part 1 and part 2 into df final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b877141d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32096a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load txt files (comma-separated) and convert to DataFrames then save to CSV\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the two parts of the final web data and split by the separator comma \",\"\u001b[39;00m\n\u001b[32m      4\u001b[39m df_final_web_data_pt_1 = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../data/raw/df_final_web_data_pt_1.txt\u001b[39m\u001b[33m\"\u001b[39m,sep=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load txt files (comma-separated) and convert to DataFrames then save to CSV\n",
    "# Load the two parts of the final web data and split by the separator comma \",\"\n",
    "df_final_web_data_pt_1 = pd.read_csv(\"../data/raw/df_final_web_data_pt_1.txt\",sep=\",\")\n",
    "df_final_web_data_pt_2 = pd.read_csv(\"../data/raw/df_final_web_data_pt_2.txt\",sep=\",\")\n",
    "\n",
    "# Display the 2 DataFrames to ensure they loaded correctly\n",
    "display(df_final_web_data_pt_1.head())\n",
    "display(df_final_web_data_pt_2.head())\n",
    "\n",
    "# Save each DataFrame to CSV\n",
    "df_final_web_data_pt_1.to_csv(\"../data/interim/df_final_web_data_pt_1.csv\",index=False)\n",
    "df_final_web_data_pt_2.to_csv(\"../data/interim/df_final_web_data_pt_2.csv\",index=False)\n",
    "\n",
    "# Merge the two parts (same columns)\n",
    "df_final_experiment_clients = pd.concat([df_final_web_data_pt_1, df_final_web_data_pt_2],ignore_index=True)\n",
    "df_final_experiment_clients.to_csv('../data/df_final_web_data.csv', index=False)\n",
    "\n",
    "# Save merged CSV\n",
    "df_final_experiment_clients.to_csv(\"../data/processed/final_web_data_merged.csv\",index=False)\n",
    "print(\"Date and time columns added and saved in 'df_final_web_data.csv'\")\n",
    "\n",
    "# Display the merged DataFrame to ensure it loaded correctly\n",
    "display(df_final_experiment_clients.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5f3fc",
   "metadata": {},
   "source": [
    "---\n",
    "### STEP 02: Merge & Save in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save each part as CSV\n",
    "df_final_web_data_pt_1.to_csv(\"../data/interim/final_web_data_pt_1.csv\",index=False)\n",
    "df_final_web_data_pt_2.to_csv(\"../data/interim/final_web_data_pt_2.csv\",index=False)\n",
    "\n",
    "# Merge the two parts (same columns)\n",
    "df_final_experiment_clients = pd.concat([df_final_web_data_pt_1, df_final_web_data_pt_2],ignore_index=True)\n",
    "df_final_experiment_clients.to_csv('../data/df_final_web_data.csv', index=False)\n",
    "# Save merged CSV\n",
    "df_final_experiment_clients.to_csv(\"../data/processed/final_web_data_merged.csv\",index=False)\n",
    "print(\"Date and time columns added and saved in 'df_final_web_data.csv'\")\n",
    "# Display the merged DataFrame to ensure it loaded correctly\n",
    "display(df_final_experiment_clients.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c793335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv to verify\n",
    "digital_footprints = pd.read_csv('../data/df_final_web_data.csv')\n",
    "digital_footprints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985c456",
   "metadata": {},
   "source": [
    "---\n",
    "### Load the 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# client_profiles dataset\n",
    "client_profiles = pd.read_csv(\"../data/df_final_demo.csv\")\n",
    "\n",
    "# digital_footprints dataset (main dataset for client behaviour)\n",
    "digital_footprints = pd.read_csv(\"../data/df_final_web_data.csv\")\n",
    "\n",
    "# experiment_roster dataset\n",
    "experiment_roster = pd.read_csv(\"../data/df_final_experiment_clients.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08403e",
   "metadata": {},
   "source": [
    "### First View of the 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1df705",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_footprints.head()\n",
    "digital_footprints.shape()\n",
    "digital_footprints.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8a5d4",
   "metadata": {},
   "source": [
    "---\n",
    "### Dealing with null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d08cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SABINA COMMENT: What do you gather from this chart?\n",
    "\n",
    "# SABINA COMMENT: Your logons_6months variable is not well-formatted, this\n",
    "# chart is completely wrong (even though the idea is useful). Please re-do.\n",
    "\n",
    "# Deal with Null values for Process step composition by variation (normalized 1)\n",
    "\n",
    "# document in detail for each cleaning step next to its code and plot\n",
    "\n",
    "# fixes like from this 15K to 15000\n",
    "# a = \"15K\" # info correct but can't calculate with it unless corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fbe61d",
   "metadata": {},
   "source": [
    "---\n",
    "### Load the 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# combine datasets part 1 and part 2\n",
    "\n",
    "# client_profiles dataset\n",
    "client_profiles = pd.read_csv(\"../data/df_final_demo.csv\")\n",
    "\n",
    "# digital_footprints dataset (main dataset)\n",
    "digital_footprints = pd.read_csv(\"../data/df_final_web_data.csv\")\n",
    "\n",
    "# experiment_roster dataset\n",
    "experiment_roster = pd.read_csv(\"../data/df_final_experiment_clients.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70fcad9",
   "metadata": {},
   "source": [
    "---\n",
    "### First View of the 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ddbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_footprints.head()\n",
    "digital_footprints.shape()\n",
    "digital_footprints.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
